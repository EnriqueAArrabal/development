{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# GLIP-Large en COCO val2017 (vehículos) con thresholds bajos\n",
    "# ==============================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from transformers import GLIPProcessor, GLIPForObjectDetection\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----- 1️⃣ COCO dataset -----\n",
    "dataDir = \"./COCO\"\n",
    "dataType = \"val2017\"\n",
    "annFile = os.path.join(dataDir, \"annotations\", f\"instances_{dataType}.json\")\n",
    "coco_gt = COCO(annFile)\n",
    "\n",
    "vehicle_classes = ['car', 'bus', 'truck', 'bicycle', 'motorcycle']\n",
    "cat_ids = coco_gt.getCatIds(catNms=vehicle_classes)\n",
    "\n",
    "# Obtener todas las imágenes que tengan al menos una categoría de vehículo\n",
    "img_ids_set = set()\n",
    "for cat_id in cat_ids:\n",
    "    ids = coco_gt.getImgIds(catIds=[cat_id])\n",
    "    img_ids_set.update(ids)\n",
    "\n",
    "img_ids = list(img_ids_set)\n",
    "images = coco_gt.loadImgs(img_ids)\n",
    "\n",
    "print(f\"{len(images)} imágenes con al menos un vehículo encontradas.\")\n",
    "\n",
    "# ----- 2️⃣ Cargar GLIP-Large -----\n",
    "model_id = \"Salesforce/glip-large\"\n",
    "processor = GLIPProcessor.from_pretrained(model_id)\n",
    "model = GLIPForObjectDetection.from_pretrained(model_id).to(device)\n",
    "model.eval()\n",
    "\n",
    "# ----- 3️⃣ Inferencia y conversión a formato COCO -----\n",
    "coco_results = []\n",
    "\n",
    "for img in tqdm(images, desc=\"Procesando imágenes\"):\n",
    "    img_path = os.path.join(dataDir, \"images\", dataType, img['file_name'])\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    width, height = image.size\n",
    "\n",
    "    # Preparar inputs\n",
    "    inputs = processor(images=image, text=vehicle_classes, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Postprocesar detecciones\n",
    "    # GLIP devuelve bounding boxes en normalized coordinates\n",
    "    target_sizes = torch.tensor([[height, width]], device=device)\n",
    "    results = processor.post_process_object_detection(outputs, threshold=0.25, target_sizes=target_sizes)[0]\n",
    "\n",
    "    # Dibujar detecciones y guardar en formato COCO\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        label_text = vehicle_classes[label] if label < len(vehicle_classes) else \"unknown\"\n",
    "        x1, y1, x2, y2 = box.tolist()\n",
    "        coco_results.append({\n",
    "            \"image_id\": img['id'],\n",
    "            \"category_id\": coco_gt.getCatIds(catNms=[label_text])[0],\n",
    "            \"bbox\": [x1, y1, x2-x1, y2-y1],\n",
    "            \"score\": float(score)\n",
    "        })\n",
    "        # Dibujar\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n",
    "        draw.text((x1, y1-10), f\"{label_text}: {score:.2f}\", fill=\"red\")\n",
    "\n",
    "# ----- 4️⃣ Guardar resultados -----\n",
    "with open(\"glip_large_highrec.json\", \"w\") as f:\n",
    "    json.dump(coco_results, f)\n",
    "\n",
    "print(f\"Resultados guardados: {len(coco_results)} detecciones\")\n",
    "\n",
    "# ----- 5️⃣ Evaluación COCO -----\n",
    "if len(coco_results) > 0:\n",
    "    coco_dt = coco_gt.loadRes(\"glip_large_highrec.json\")\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iouType='bbox')\n",
    "    coco_eval.params.catIds = cat_ids\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "else:\n",
    "    print(\"No se detectaron objetos, ajusta thresholds o prompt.\")\n",
    "\n",
    "# Mostrar última imagen procesada\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
